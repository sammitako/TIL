{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 로지스틱 회귀 (Multiple Logistic Regression)\n",
    "## 합격 여부 예측 모델\n",
    "* 독립변수 - GRE, GPA, RANK\n",
    "* 종속변수 - 합격여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# warning off\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('admission.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit    0\n",
      "gre      0\n",
      "gpa      0\n",
      "rank     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치 처리 (Z-score)\n",
    "#### Boxplot을 이용하여 이상치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig_gre = fig.add_subplot(1,3, 1)\n",
    "fig_gpa = fig.add_subplot(1,3, 2)\n",
    "fig_rank = fig.add_subplot(1,3, 3)\n",
    "\n",
    "fig_gre.boxplot(df['gre'])\n",
    "fig_gre.set_title('gre')\n",
    "\n",
    "fig_gpa.boxplot(df['gpa'])\n",
    "fig_gpa.set_title('gpa')\n",
    "\n",
    "fig_rank.boxplot(df['rank'])\n",
    "fig_rank.set_title('rank')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연습용이니까 이상치 제거\n",
    "위의 이상치들은 실제 데이터이므로 현업에서는 제거를 하지 않는 쪽으로 갈 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: admit, dtype: int64)\n",
      "71     300\n",
      "100    340\n",
      "119    340\n",
      "179    300\n",
      "216    340\n",
      "304    220\n",
      "315    300\n",
      "316    340\n",
      "Name: gre, dtype: int64\n",
      "17     2.56\n",
      "40     2.42\n",
      "48     2.48\n",
      "156    2.52\n",
      "176    2.62\n",
      "289    2.26\n",
      "294    2.55\n",
      "372    2.42\n",
      "384    2.62\n",
      "397    2.63\n",
      "Name: gpa, dtype: float64\n",
      "Series([], Name: rank, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "394      1  460  3.99     3\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[382 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zscore_threshold = 2.0 # 2.0 이하로 설정하는 것이 optimal 하다.\n",
    "\n",
    "for col in df.columns:\n",
    "    outlier = df[col][np.abs(stats.zscore(df[col])) > zscore_threshold]\n",
    "    print(outlier)\n",
    "    \n",
    "    df = df.loc[~df[col].isin(outlier)]\n",
    "\n",
    "display(df) # 382 rows × 4 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Set\n",
    "* Scikit-learn 용도\n",
    "* 결측치, 이상치만 처리된 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380.     3.61   3.  ]\n",
      " [660.     3.67   3.  ]\n",
      " [800.     4.     1.  ]\n",
      " ...\n",
      " [560.     3.04   3.  ]\n",
      " [700.     3.65   2.  ]\n",
      " [600.     3.89   3.  ]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "x_data = df.drop('admit', axis=1, inplace=False).values # 2차원 ndarray 복사본 \n",
    "t_data = df['admit'].values.reshape(-1,1) # Series -> 1차원 ndarray 벡터 -> 2차원 행렬\n",
    "\n",
    "print(x_data)\n",
    "print(t_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화 (Min-Max)\n",
    "* python\n",
    "* tenforflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04545455, 0.71111111, 0.66666667],\n",
       "       [0.68181818, 0.75555556, 0.66666667],\n",
       "       [1.        , 1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.45454545, 0.28888889, 0.66666667],\n",
       "       [0.77272727, 0.74074074, 0.33333333],\n",
       "       [0.54545455, 0.91851852, 0.66666667]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data)\n",
    "norm_x_data = scaler_x.transform(x_data)\n",
    "\n",
    "display(norm_x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [0.8535424  0.13805928 0.23890212], b: [0.71021549], loss: 437.3074662776721\n",
      "W: [ 1.07521955  1.12939476 -1.61510775], b: [-1.25306746], loss: 221.21560007990126\n",
      "W: [ 1.07526591  1.12942595 -1.61508268], b: [-1.25312616], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n",
      "W: [ 1.07526592  1.12942595 -1.61508268], b: [-1.25312617], loss: 221.21560006866997\n"
     ]
    }
   ],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    # f: cross entropy, x: [W1, W2, W3, b]\n",
    "    delta_x = 1e-4\n",
    "    derivative_x = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp = x[idx]\n",
    "        \n",
    "        x[idx] = tmp + delta_x\n",
    "        fx_plus_delta = f(x)\n",
    "        \n",
    "        x[idx] = tmp - delta_x\n",
    "        fx_minus_delta = f(x)\n",
    "        \n",
    "        derivative_x[idx] = (fx_plus_delta - fx_minus_delta) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp\n",
    "        it.iternext()\n",
    "    \n",
    "    return derivative_x\n",
    "\n",
    "# training data set: norm_x_data, t_data\n",
    "\n",
    "# W, b\n",
    "W = np.random.rand(3,1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "# loss function\n",
    "def loss_func(input_obj): # [W1 W2 W3 b]\n",
    "    input_W = input_obj[:-1].reshape(-1,1) # 3행 1열\n",
    "    input_b = input_obj[-1:]\n",
    "    \n",
    "    # linear regression model\n",
    "    z = np.dot(norm_x_data, input_W) + input_b\n",
    "    \n",
    "    # logistic regression model\n",
    "    y = 1 / (1 + np.exp(-1 * z))\n",
    "    \n",
    "    # cross entropy\n",
    "    delta = 1e-7\n",
    "    log_loss = -np.sum(t_data*np.log(y+delta) + (1 - t_data)*np.log(1 - y+delta))\n",
    "    \n",
    "    return log_loss\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# learning - gradient descent algorithm\n",
    "for step in range(300000):\n",
    "    # [W1 W2 W3 b]\n",
    "    input_param = np.concatenate((W.ravel(), b.ravel()), axis=0)\n",
    "    \n",
    "    # learning_rate * 편미분\n",
    "    derivative_result = learning_rate * numerical_derivative(loss_func, input_param)\n",
    "    \n",
    "    # W, b 갱신\n",
    "    W = W - derivative_result[:-1].reshape(-1,1) # 3행 1열\n",
    "    b = b - derivative_result[-1:]\n",
    "    \n",
    "    if step % 30000 == 0:\n",
    "        input_param = np.concatenate((W.ravel(), b.ravel()), axis=0)\n",
    "        print('W: {}, b: {}, loss: {}'.format(W.ravel(), b, loss_func(input_param)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Prediction\n",
    "* GRE: 600\n",
    "* GPA: 3.8\n",
    "* RANK: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, array([[0.57333869]]))\n"
     ]
    }
   ],
   "source": [
    "def logistic_predict(x):\n",
    "    z = np.dot(x, W) + b\n",
    "    y = 1 / (1 + np.exp(-1 * z))\n",
    "    \n",
    "    if y < 0.5:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = 1\n",
    "        \n",
    "    return result, y\n",
    "\n",
    "predict_data = np.array([[600, 3.8, 1]])\n",
    "scaled_predict_data = scaler_x.transform(predict_data)\n",
    "\n",
    "result_python = logistic_predict(scaled_predict_data)\n",
    "print(result_python) # (합격여부, 합격확률)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [ 1.5168793  0.6140489 -1.3132479], b: [0.43858263], loss: 0.9228240251541138\n",
      "W: [ 1.1516572   0.25317657 -1.6401677 ], b: [-0.2331678], loss: 0.6135178804397583\n",
      "W: [ 1.0487156  0.17181   -1.7276431], b: [-0.43620571], loss: 0.5887900590896606\n",
      "W: [ 1.0199159   0.16774003 -1.7539514 ], b: [-0.5102186], loss: 0.58623206615448\n",
      "W: [ 1.012842    0.18578877 -1.7626314 ], b: [-0.5459838], loss: 0.5856351852416992\n",
      "W: [ 1.012417    0.21006644 -1.7659119 ], b: [-0.569604], loss: 0.5852476954460144\n",
      "W: [ 1.0139297   0.23574261 -1.7659119 ], b: [-0.5889385], loss: 0.584901750087738\n",
      "W: [ 1.0173526   0.26096645 -1.7659119 ], b: [-0.60681987], loss: 0.5845784544944763\n",
      "W: [ 1.0208498  0.2855481 -1.7659119], b: [-0.62470126], loss: 0.5842703580856323\n",
      "W: [ 1.0229455   0.30962875 -1.7659119 ], b: [-0.64089644], loss: 0.5839857459068298\n"
     ]
    }
   ],
   "source": [
    "# training data set: norm_x_data, t_data\n",
    "\n",
    "# X, T\n",
    "X = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random.normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# model\n",
    "linear_model = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(linear_model)\n",
    "\n",
    "# log loss\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=linear_model, labels=T))\n",
    "\n",
    "# gradient descent algorithm\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# learning\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(300000):\n",
    "    _, W_val, b_val, loss_val = sess.run([train, W, b, loss], feed_dict={X: norm_x_data, T: t_data})\n",
    "    \n",
    "    if step % 30000 == 0:\n",
    "        print('W: {}, b: {}, loss: {}'.format(W_val.ravel(), b_val, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Prediction\n",
    "* GRE: 600\n",
    "* GPA: 3.8\n",
    "* RANK: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54632527]]\n"
     ]
    }
   ],
   "source": [
    "predict_data = np.array([[600, 3.8, 1]])\n",
    "scaled_predict_data = scaler_x.transform(predict_data)\n",
    "result_tensorflow = sess.run(H, feed_dict={X: scaled_predict_data})\n",
    "\n",
    "print(result_tensorflow) # [[0.54632527]] 확률로 합격"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[ 0.00253619  0.74560063 -0.52891027]], b: [-3.57439949], 확률: [[0.43740782 0.56259218]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# training datat set: x_data, t_data\n",
    "# model\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# learning\n",
    "model.fit(x_data, t_data.ravel())\n",
    "\n",
    "# prediction\n",
    "result = model.predict(predict_data)\n",
    "result_proba = model.predict_proba(predict_data)\n",
    "\n",
    "print('W: {}, b: {}, 확률: {}'.format(model.coef_, model.intercept_, result_proba))\n",
    "print(result) # 1: 합격"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
